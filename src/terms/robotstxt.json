{
    "title": "robots.txt",
    "types": [
        "glossary",
        "usage"
    ],
    "formTypes": {
        "robots.txt": [
            "n"
        ]
    },
    "synonyms": [],
    "primarySource": "UserDocs",
    "contentTags": [
        "Design",
        "Programming"
    ],
    "userTags": [
        "Internal",
        "Merchant"
    ],
    "shortDefinition": "A file placed on a website that tells search-engine crawlers which pages not to index.",
    "usage": "Not capitalized. Pronounced “robots dot text”."
}